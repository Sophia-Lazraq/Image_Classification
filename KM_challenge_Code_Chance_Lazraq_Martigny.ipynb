{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Methods Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By : Olivier Chance, Sophia Lazraq, Peter Martigny \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filiation : M2 Data Sciences , Université Paris-Saclay, Ecole Polytechnique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cvxopt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Helper:\n",
    "    \n",
    "    @staticmethod\n",
    "    def log_process(title, cursor, finish_cursor, start_time = None):\n",
    "        percentage = float(cursor + 1)/finish_cursor\n",
    "        now_time = time()\n",
    "        time_to_finish = ((now_time - start_time)/percentage) - (now_time - start_time)\n",
    "        mn, sc = int(time_to_finish//60), int((time_to_finish/60 - time_to_finish//60)*60)\n",
    "        if start_time:\n",
    "            sys.stdout.write(\"\\r%s - %.2f%% ----- Temps restant estimé: %d min %d sec -----\" %(title, 100*percentage, mn, sc))\n",
    "            sys.stdout.flush()\n",
    "        else:\n",
    "            sys.stdout.write(\"\\r%s - \\r%.2f%%\" %(title, 100*percentage))\n",
    "            sys.stdout.flush()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extractor : SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SIFT:\n",
    "\n",
    "    ###################\n",
    "    #    CONSTUCTOR   #\n",
    "    ###################\n",
    "\n",
    "    def __init__(self, gs = 8, ps = 16, gaussian_thres = 1.0, gaussian_sigma = 0.8, sift_thres = 0.2, \\\n",
    "                 num_angles = 12, num_bins = 5, alpha = 9.0):\n",
    "        self.num_angles = num_angles\n",
    "        self.num_bins = num_bins\n",
    "        self.alpha = alpha\n",
    "        self.angle_list = np.array(range(num_angles))*2.0*np.pi/num_angles\n",
    "        self.gs = gs\n",
    "        self.ps = ps\n",
    "        self.gaussian_thres = gaussian_thres\n",
    "        self.gaussian_sigma = gaussian_sigma\n",
    "        self.sift_thres = sift_thres\n",
    "        self.weights = self._get_weights(num_bins)\n",
    "\n",
    "    ###################\n",
    "    # PUBLIC  METHODS #\n",
    "    ###################\n",
    "\n",
    "    def get_params_image(self, image):\n",
    "        image = image.astype(np.double)\n",
    "        if image.ndim == 3:\n",
    "            image = np.mean(image, axis=2)\n",
    "        H, W = image.shape\n",
    "        gS = self.gs\n",
    "        pS = self.ps\n",
    "        remH = np.mod(H-pS, gS)\n",
    "        remW = np.mod(W-pS, gS)\n",
    "        offsetH = remH/2\n",
    "        offsetW = remW/2\n",
    "        gridH, gridW = np.meshgrid(range(offsetH, H-pS+1, gS), range(offsetW, W-pS+1, gS))\n",
    "        gridH = gridH.flatten()\n",
    "        gridW = gridW.flatten()\n",
    "        features = self._calculate_sift_grid(image, gridH, gridW)\n",
    "        features = self._normalize_sift(features)\n",
    "        positions = np.vstack((gridH / np.double(H), gridW / np.double(W)))\n",
    "        return features, positions\n",
    "    \n",
    "    def get_X(self, data):\n",
    "        out = []\n",
    "        start = time()\n",
    "        finish = len(data)\n",
    "        for idx, dt in enumerate(data):\n",
    "            Helper.log_process('SIFT', idx, finish_cursor=finish, start_time = start)\n",
    "            out.append(self.get_params_image(np.mean(np.double(dt), axis=2))[0][0])\n",
    "        return np.array(out)\n",
    "\n",
    "    \n",
    "    ###################\n",
    "    # PRIVATE METHODS #\n",
    "    ###################\n",
    "\n",
    "    def _get_weights(self, num_bins):\n",
    "        size_unit = np.array(range(self.ps))\n",
    "        sph, spw = np.meshgrid(size_unit, size_unit)\n",
    "        sph.resize(sph.size)\n",
    "        spw.resize(spw.size)\n",
    "        bincenter = np.array(range(1, num_bins*2, 2)) / 2.0 / num_bins * self.ps - 0.5\n",
    "        bincenter_h, bincenter_w = np.meshgrid(bincenter, bincenter)\n",
    "        bincenter_h.resize((bincenter_h.size, 1))\n",
    "        bincenter_w.resize((bincenter_w.size, 1))\n",
    "        dist_ph = abs(sph - bincenter_h)\n",
    "        dist_pw = abs(spw - bincenter_w)\n",
    "        weights_h = dist_ph / (self.ps / np.double(num_bins))\n",
    "        weights_w = dist_pw / (self.ps / np.double(num_bins))\n",
    "        weights_h = (1-weights_h) * (weights_h <= 1)\n",
    "        weights_w = (1-weights_w) * (weights_w <= 1)\n",
    "        return weights_h * weights_w\n",
    "\n",
    "    def _calculate_sift_grid(self, image, gridH, gridW):\n",
    "        H, W = image.shape\n",
    "        Npatches = gridH.size\n",
    "        features = np.zeros((Npatches, self.num_bins * self.num_bins * self.num_angles))\n",
    "        gaussian_height, gaussian_width = self._get_gauss_filter(self.gaussian_sigma)\n",
    "        IH = self._convolution2D(image, gaussian_height)\n",
    "        IW = self._convolution2D(image, gaussian_width)\n",
    "        Imag = np.sqrt(IH**2 + IW**2)\n",
    "        Itheta = np.arctan2(IH,IW)\n",
    "        Iorient = np.zeros((self.num_angles, H, W))\n",
    "        for i in range(self.num_angles):\n",
    "            Iorient[i] = Imag * np.maximum(np.cos(Itheta - self.angle_list[i])**self.alpha, 0)\n",
    "        for i in range(Npatches):\n",
    "            currFeature = np.zeros((self.num_angles, self.num_bins**2))\n",
    "            for j in range(self.num_angles):\n",
    "                currFeature[j] = np.dot(self.weights,\\\n",
    "                        Iorient[j,gridH[i]:gridH[i]+self.ps, gridW[i]:gridW[i]+self.ps].flatten())\n",
    "            features[i] = currFeature.flatten()\n",
    "        return features\n",
    "\n",
    "    def _normalize_sift(self, features):\n",
    "        siftlen = np.sqrt(np.sum(features**2, axis=1))\n",
    "        hcontrast = (siftlen >= self.gaussian_thres)\n",
    "        siftlen[siftlen < self.gaussian_thres] = self.gaussian_thres\n",
    "        features /= siftlen.reshape((siftlen.size, 1))\n",
    "        features[features>self.sift_thres] = self.sift_thres\n",
    "        features[hcontrast] /= np.sqrt(np.sum(features[hcontrast]**2, axis=1)).\\\n",
    "                reshape((features[hcontrast].shape[0], 1))\n",
    "        return features\n",
    "\n",
    "\n",
    "    def _get_gauss_filter(self, sigma):\n",
    "        gaussian_filter_amp = np.int(2*np.ceil(sigma))\n",
    "        gaussian_filter = np.array(range(-gaussian_filter_amp, gaussian_filter_amp+1))**2\n",
    "        gaussian_filter = gaussian_filter[:, np.newaxis] + gaussian_filter\n",
    "        gaussian_filter = np.exp(- gaussian_filter / (2.0 * sigma**2))\n",
    "        gaussian_filter /= np.sum(gaussian_filter)\n",
    "        gaussian_height, gaussian_width = np.gradient(gaussian_filter)\n",
    "        gaussian_height *= 2.0/np.sum(np.abs(gaussian_height))\n",
    "        gaussian_width  *= 2.0/np.sum(np.abs(gaussian_width))\n",
    "        return gaussian_height, gaussian_width\n",
    "    \n",
    "    def _convolution2D(self, image, kernel):\n",
    "        imRows, imCols = image.shape\n",
    "        kRows, kCols = kernel.shape\n",
    "\n",
    "        y = np.zeros((imRows,imCols))\n",
    "\n",
    "        kcenterX = kCols//2\n",
    "        kcenterY = kRows//2\n",
    "\n",
    "        for i in range(imRows):\n",
    "            for j in range(imCols):\n",
    "                for m in range(kRows):\n",
    "                    mm = kRows - 1 - m\n",
    "                    for n in range(kCols):\n",
    "                        nn = kCols - 1 - n\n",
    "\n",
    "                        ii = i + (m - kcenterY)\n",
    "                        jj = j + (n - kcenterX)\n",
    "\n",
    "                        if ii >= 0 and ii < imRows and jj >= 0 and jj < imCols :\n",
    "                            y[i][j] += image[ii][jj] * kernel[mm][nn]\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected Kernel : Chi-square Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Kernel:\n",
    "    \n",
    "    ########################\n",
    "    # Only static  methods #\n",
    "    ########################\n",
    "    \n",
    "    @staticmethod\n",
    "    def linear():\n",
    "        def f(X1, X2):\n",
    "            return X1.dot(X2.T)\n",
    "        return f\n",
    "    \n",
    "    @staticmethod\n",
    "    def chi2(gamma):\n",
    "        def f(X1, X2):\n",
    "            out = np.zeros((X1.shape[0], X2.shape[0]))\n",
    "            n_X1 = X1.shape[0]\n",
    "            n_X2 = X2.shape[0]\n",
    "            n_features = X1.shape[1]\n",
    "\n",
    "            for i in range(n_X1):\n",
    "                for j in range(n_X2):\n",
    "                    p = 0\n",
    "                    for k in range(n_features):\n",
    "                        denominateur = (X1[i, k] - X2[j, k])\n",
    "                        nominateur = (X1[i, k] + X2[j, k])\n",
    "                        if nominateur != 0:\n",
    "                            p += denominateur * denominateur / nominateur\n",
    "                    out[i, j] = -p\n",
    "            tmp = gamma * out\n",
    "            return  np.exp(tmp, tmp)        \n",
    "        return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selected Classifier : SVM multi-calss using QP solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SVC:\n",
    "    \n",
    "    ###############\n",
    "    # Constructor #\n",
    "    ###############\n",
    "    \n",
    "    def __init__(self, C=1.0, kernel='linear', gamma=.1, degree=2):\n",
    "        assert kernel in ['linear', 'chi2'], 'Kernel has to be linear or chi2'\n",
    "        self.C = C\n",
    "        self.degree = degree\n",
    "        self.gamma = gamma\n",
    "        self.kernel = self._get_kernel(kernel, gamma=gamma, degree=degree)\n",
    "    \n",
    "    ##################\n",
    "    # Public methods #\n",
    "    ##################\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self._X, self._y = X, y\n",
    "        \n",
    "        self.labels = np.unique(y)\n",
    "        self.n_labels = len(self.labels)\n",
    "        self._K = self.kernel(X, X)\n",
    "        \n",
    "        # OneVsAll\n",
    "        models = {}\n",
    "        start = time()\n",
    "        finish = len(self.labels)\n",
    "        for idx, label in enumerate(self.labels[:3]):\n",
    "            models[label] = {}\n",
    "            y_label = np.array([1. if e == label else -1. for e in y])\n",
    "            w, b, mu_support, idx_support = self._fit_binary(X, y_label)\n",
    "            \n",
    "            models[label]['y'] = y_label\n",
    "            models[label]['w'] = w\n",
    "            models[label]['b'] = b  \n",
    "            models[label]['mu_support'] = mu_support\n",
    "            models[label]['idx_support'] = idx_support\n",
    "            \n",
    "            Helper.log_process('SVC Fitting', idx, finish_cursor=finish, start_time = start)\n",
    "            \n",
    "        self.models = models\n",
    "            \n",
    "    def get_params(self):\n",
    "        return {\n",
    "            'X': self._X,\n",
    "            'y': self._y,\n",
    "            'K': self._K,\n",
    "            'n_labels': self.n_labels,\n",
    "            'labels': self.labels,\n",
    "            'models': self.models,\n",
    "            'C': self.C,\n",
    "            'degree': self.degree,\n",
    "            'gamma': self.gamma,\n",
    "            'training_score': self.score(self._X, self._y)\n",
    "        }\n",
    "    \n",
    "    def set_params(self, params):\n",
    "        self._X = params['X']\n",
    "        self._y = params['y']\n",
    "        self._K = params['K']\n",
    "        self.n_labels = params['n_labels']\n",
    "        self.labels = params['labels']\n",
    "        self.models = params['models']\n",
    "        self.C = params['C']\n",
    "        self.degree = params['degree']\n",
    "        self.gamma = params['gamma']\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.labels[np.argmax(np.array([self._predict(X, self.models[label]['y'], self.models[label]['idx_support'], self.models[label]['mu_support'], self.models[label]['b']) for label in self.labels]), axis=0)]\n",
    "        \n",
    "    def score(self, X, y):\n",
    "        return np.mean(self.predict(X) == y)\n",
    "    \n",
    "    ###################\n",
    "    # Private methods #\n",
    "    ###################\n",
    "        \n",
    "    def _qp(self, H, e, A, b, C=np.inf, l=1e-8, verbose=True):\n",
    "        # Gram matrix\n",
    "        n = H.shape[0]\n",
    "        H = cvxopt.matrix(H)\n",
    "        A = cvxopt.matrix(A, (1, n))\n",
    "        e = cvxopt.matrix(-e)\n",
    "        b = cvxopt.matrix(0.0)\n",
    "        if C == np.inf:\n",
    "            G = cvxopt.matrix(np.diag(np.ones(n) * -1))\n",
    "            h = cvxopt.matrix(np.zeros(n))\n",
    "        else:\n",
    "            G = cvxopt.matrix(np.concatenate([np.diag(np.ones(n) * -1),\n",
    "                                             np.diag(np.ones(n))], axis=0))\n",
    "            h = cvxopt.matrix(np.concatenate([np.zeros(n), C * np.ones(n)]))\n",
    "\n",
    "        # Solve QP problem\n",
    "        cvxopt.solvers.options['show_progress'] = verbose\n",
    "        solution = cvxopt.solvers.qp(H, e, G, h, A, b)\n",
    "\n",
    "        # Lagrange multipliers\n",
    "        mu = np.ravel(solution['x'])\n",
    "        return mu\n",
    "    \n",
    "    def _predict(self, X, y_model, idx_support, mu_support, b):\n",
    "        X_support = self._X[idx_support]\n",
    "        G = self.kernel(X, X_support)\n",
    "        return G.dot(mu_support * y_model[idx_support]) + b\n",
    "    \n",
    "    def _fit_binary(self, X, y):\n",
    "        mu_support, idx_support = self._svm_solver_non_sep(self._K, y, self.C)\n",
    "        w = self._get_w(mu_support, idx_support, X, y)\n",
    "        b = self._compute_b(self._K, y, mu_support, idx_support)\n",
    "        return w, b, mu_support, idx_support\n",
    "    \n",
    "    def _svm_solver_non_sep(self, K, y, C):\n",
    "        n = y.shape[0]\n",
    "        y = y.reshape((n, 1))\n",
    "        H = np.dot(y, y.T)*K\n",
    "        e = np.ones(n)\n",
    "        A = y\n",
    "        b = np.zeros(n)\n",
    "        mu = self._qp(H, e, A, b, C, l=1e-8, verbose=False)\n",
    "        idx_support = np.where(np.abs(mu) > 1e-5)[0]\n",
    "        mu_support = mu[idx_support]\n",
    "        return mu_support, idx_support\n",
    "    \n",
    "    def _get_w(self, mu_support, idx_support, X, y):\n",
    "        return np.sum((mu_support * y[idx_support])[: , None] * X[idx_support], axis=0)\n",
    "    \n",
    "    def _get_kernel(self, kernel, gamma, degree):\n",
    "        return {\n",
    "            'linear': Kernel.linear(),\n",
    "            'chi2': Kernel.chi2(gamma)\n",
    "        }[kernel]\n",
    "\n",
    "    def _compute_b(self, K, y, mu_support, idx_support):\n",
    "        num_support_vector = idx_support.size\n",
    "        y_support = y[idx_support]\n",
    "        K_support = K[idx_support][:, idx_support]\n",
    "        b = [y_support[j] - sum([mu_support[i]*y_support[i]*K_support[i][j] for i in range(num_support_vector)]) for j in range(num_support_vector)]\n",
    "        return np.mean(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ImageTransformation:\n",
    "    \n",
    "    ########################\n",
    "    # Only static  methods #\n",
    "    ########################\n",
    "\n",
    "    @staticmethod\n",
    "    def flip_image_horizontal(image):\n",
    "        # Takes an image as input and outputs the same image with a horizontal flip\n",
    "        result = image.copy()\n",
    "        for channel in range(3):\n",
    "            aux = image[:, :, channel]\n",
    "            for column in range(len(aux)):\n",
    "                result[:, column, channel] = aux[:, len(aux) - column - 1]\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_df = pd.read_csv('./Xtr.csv', header=None)\n",
    "y_df = pd.read_csv('./Ytr.csv')\n",
    "X_df = X_df.loc[:,:3071]\n",
    "\n",
    "X_test = pd.read_csv('./Xte.csv', header=None)\n",
    "X_test = X_test.loc[:,:3071]\n",
    "\n",
    "X = X_df.values\n",
    "y = y_df.Prediction\n",
    "\n",
    "X_test = X_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Colored images\n",
    "red, green, blue = np.hsplit(X, 3)\n",
    "data = np.array([np.dstack((red[i], blue[i], green[i])).reshape(32, 32, 3) for i in range(len(X))])\n",
    "\n",
    "red, green, blue = np.hsplit(X_test, 3)\n",
    "data_test = np.array([np.dstack((red[i], blue[i], green[i])).reshape(32, 32, 3) for i in range(len(X_test))])\n",
    "\n",
    "# Gray images - Just for visualisation purpose (train set)\n",
    "X_black_and_white = np.sum(np.hsplit(X, 3), axis=0)/3\n",
    "data_gray = np.array([X_black_and_white[i].reshape((32, 32)) for i in range(len(X))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flipping image... - 100.00% ----- Temps restant estimé: 0 min 0 sec -----"
     ]
    }
   ],
   "source": [
    "# Flipping image from the train set\n",
    "start = time()\n",
    "finish = len(data)\n",
    "\n",
    "augmented_train = []\n",
    "\n",
    "for row in range(0, finish):\n",
    "    if row % 50 == 0 or row == finish-1:\n",
    "        Helper.log_process('Flipping image...', row, finish_cursor=finish, start_time = start)\n",
    "    augmented_train.append(data[row])\n",
    "    augmented_train.append(ImageTransformation.flip_image_horizontal(data[row]))\n",
    "\n",
    "augmented_train=np.array(augmented_train)\n",
    "    \n",
    "# Compute augmented labels\n",
    "start = time()\n",
    "augmented_labels = []\n",
    "for row in range(len(data)):\n",
    "    aux = y[row]\n",
    "    augmented_labels.append(aux)\n",
    "    augmented_labels.append(aux)\n",
    "    \n",
    "augmented_labels = np.array(augmented_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = { 'gs': 6,\n",
    "           'chi2_gamma': .6,\n",
    "           'C': 10.,\n",
    "           'ps': 31,\n",
    "           'sift_thres': .3,\n",
    "           'gaussian_thres': .7,\n",
    "           'gaussian_sigma': .4,\n",
    "           'num_angles': 12,\n",
    "           'num_bins': 5,\n",
    "           'alpha': 9.0 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the SIFT Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "extractor = SIFT(gs=params['gs'], \n",
    "                 ps=params['ps'], \n",
    "                 sift_thres=params['sift_thres'], \n",
    "                 gaussian_sigma=params['gaussian_sigma'], \n",
    "                 gaussian_thres=params['gaussian_thres'],\n",
    "                 num_angles=params['num_angles'],\n",
    "                 num_bins=params['num_bins'],\n",
    "                 alpha=params['alpha'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with_augmented_data = False ## False to be faster..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIFT - 100.00% ----- Temps restant estimé: 0 min 0 sec -----"
     ]
    }
   ],
   "source": [
    "if with_augmented_data:\n",
    "    X_train = extractor.get_X(augmented_train)\n",
    "else:\n",
    "    X_train = extractor.get_X(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = SVC(kernel='chi2', C=params['C'], gamma=params['chi2_gamma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if with_augmented_data:\n",
    "    clf.fit(X_train, augmented_labels)\n",
    "else:\n",
    "    clf.fit(X_train, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SIFT - 100.00% ----- Temps restant estimé: 0 min 0 sec -----"
     ]
    }
   ],
   "source": [
    "X_test = extractor.get_X(data_test)\n",
    "pred = clf.predict(X_test)\n",
    "predictions = pd.DataFrame(pred, columns=['Prediction'])\n",
    "predictions['id'] = np.arange(1, len(predictions)+1)\n",
    "predictions.to_csv('submission.csv', sep=',', index=False, encoding='utf-8', columns=['id', 'Prediction'])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
